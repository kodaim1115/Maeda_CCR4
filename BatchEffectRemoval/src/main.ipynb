{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HX02rumaDBHB","colab_type":"code","outputId":"5fb2f666-20c5-4593-b64b-05eac9d01484","executionInfo":{"status":"ok","timestamp":1579772675982,"user_tz":-540,"elapsed":20515,"user":{"displayName":"Kodai Minoura","photoUrl":"","userId":"11440854029320585468"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# 必要ならば以下のようにディレクトリ移動する\n","%cd /content/drive/'My Drive'/'BatchEffectRemoval-master'/src"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","/content/drive/My Drive/BatchEffectRemoval-master/src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3mtzDRpuDCHs","colab_type":"code","outputId":"7e985520-76d3-4668-9e33-94110a383b66","executionInfo":{"status":"ok","timestamp":1577689289843,"user_tz":-540,"elapsed":1539447,"user":{"displayName":"Kodai Minoura","photoUrl":"","userId":"11440854029320585468"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Calibration_Util  main.ipynb\t   __pycache__\t\tUntitled1.ipynb\n","CostFunctions.py  Monitoring.py    ScatterHist.py\tUntitled.ipynb\n","license.py\t  OUH04_calib.csv  train_MMD_ResNet.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W9kAGoNI4FWG","colab_type":"code","outputId":"3c2eeb04-ab50-4736-ccef-bcf10b7e19ec","executionInfo":{"status":"ok","timestamp":1579772740972,"user_tz":-540,"elapsed":63765,"user":{"displayName":"Kodai Minoura","photoUrl":"","userId":"11440854029320585468"}},"colab":{"base_uri":"https://localhost:8080/","height":649}},"source":["!pip install tensorflow-gpu==1.13.1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n","\u001b[K     |████████████████████████████████| 345.2MB 47kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.17.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.6)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n","Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 44.4MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 42.4MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (42.0.2)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.16.0)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n","Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S1DkLu-V9ivH","colab_type":"code","outputId":"99bcea0a-e2e4-46e1-8a8b-1af00ee08432","executionInfo":{"status":"ok","timestamp":1579772746274,"user_tz":-540,"elapsed":68143,"user":{"displayName":"Kodai Minoura","photoUrl":"","userId":"11440854029320585468"}},"colab":{"base_uri":"https://localhost:8080/","height":304}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/BatchEffectRemoval-master/src/')\n","import CostFunctions as cf\n","import Monitoring as mn\n","import ScatterHist as sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"giFVbj6b7WL2","colab_type":"code","colab":{}},"source":["sys.path.append('/content/drive/My Drive/BatchEffectRemoval-master/src/Calibration_Util')\n","import DataHandler as dh \n","import FileIO as io"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIyTk95E4nhL","colab_type":"code","outputId":"e579342f-5784-4a82-b50c-087a02a11504","executionInfo":{"status":"ok","timestamp":1577703831557,"user_tz":-540,"elapsed":5236297,"user":{"displayName":"Kodai Minoura","photoUrl":"","userId":"11440854029320585468"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["'''\n","Created on Dec 5, 2016\n","\n","@author: urishaham\n","'''\n","\n","import os.path\n","import keras.optimizers\n","#from Calibration_Util import DataHandler as dh \n","#from Calibration_Util import FileIO as io\n","from keras.layers import Input, Dense, merge, Activation, add\n","from keras.models import Model\n","from keras import callbacks as cb\n","import numpy as np\n","import matplotlib\n","from keras.layers.normalization import BatchNormalization\n","#detect display\n","import os\n","havedisplay = \"DISPLAY\" in os.environ\n","#if we have a display use a plotting backend\n","if havedisplay:\n","    matplotlib.use('TkAgg')\n","else:\n","    matplotlib.use('Agg')\n","    \n","#import CostFunctions as cf\n","#import Monitoring as mn\n","from keras.regularizers import l2\n","from sklearn import decomposition\n","from keras.callbacks import LearningRateScheduler\n","import math\n","#import ScatterHist as sh\n","from keras import initializers\n","from numpy import genfromtxt\n","import sklearn.preprocessing as prep\n","import tensorflow as tf\n","import keras.backend as K\n","\n","\n","\n","\n","\n","\n","# configuration hyper parameters\n","denoise = False # whether or not to train a denoising autoencoder to remove the zeros\n","keepProb=.8\n","\n","# AE confiduration\n","ae_encodingDim = 25\n","l2_penalty_ae = 1e-2 \n","\n","#MMD net configuration\n","mmdNetLayerSizes = [25, 25]\n","l2_penalty = 1e-2\n","#init = lambda shape, name:initializations.normal(shape, scale=.1e-4, name=name)\n","#def my_init (shape):\n","#    return initializers.normal(stddev=.1e-4)\n","#my_init = 'glorot_normal'\n","\n","#######################\n","###### read data ######\n","#######################\n","# we load two CyTOF samples \n","\n","#data = 'person1_baseline'\n","data = 'OUH16_OUH05'\n","\n","#if data =='person1_baseline':\n","#    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline.csv')\n","#    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline.csv')\n","#if data =='person2_baseline':\n","#    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline.csv')\n","#    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline.csv')\n","#if data =='person1_3month':\n","#    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month.csv')\n","#    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month.csv')\n","#if data =='person2_3month':\n","#    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month.csv')\n","#    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month.csv')\n","\n","if data =='OUH04_OUH05':\n","    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/OUH04_no_scale_imputed.csv')\n","    targetPath = os.path.join(io.DeepLearningRoot(),'Data/OUH05_no_scale_imputed.csv')\n","if data =='OUH10_OUH05':\n","    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/OUH10_no_scale_imputed.csv')\n","    targetPath = os.path.join(io.DeepLearningRoot(),'Data/OUH05_no_scale_imputed.csv')\n","if data =='OUH16_OUH05':\n","    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/OUH16_no_scale_imputed.csv')\n","    targetPath = os.path.join(io.DeepLearningRoot(),'Data/OUH05_no_scale_imputed.csv')\n","\n","   \n","source = genfromtxt(sourcePath, delimiter=',', skip_header=0)\n","target = genfromtxt(targetPath, delimiter=',', skip_header=0)\n","\n","# pre-process data: log transformation, a standard practice with CyTOF data\n","#target = dh.preProcessCytofData(target)\n","#source = dh.preProcessCytofData(source) \n","\n","numZerosOK=1\n","toKeepS = np.sum((source==0), axis = 1) <=numZerosOK\n","print(np.sum(toKeepS))\n","toKeepT = np.sum((target==0), axis = 1) <=numZerosOK\n","print(np.sum(toKeepT))\n","\n","inputDim = target.shape[1]\n","\n","if denoise:\n","    trainTarget_ae = np.concatenate([source[toKeepS], target[toKeepT]], axis=0)\n","    np.random.shuffle(trainTarget_ae)\n","    trainData_ae = trainTarget_ae * np.random.binomial(n=1, p=keepProb, size = trainTarget_ae.shape)\n","    input_cell = Input(shape=(inputDim,))\n","    encoded = Dense(ae_encodingDim, activation='relu',W_regularizer=l2(l2_penalty_ae))(input_cell)\n","    encoded1 = Dense(ae_encodingDim, activation='relu',W_regularizer=l2(l2_penalty_ae))(encoded)\n","    decoded = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty_ae))(encoded1)\n","    autoencoder = Model(input=input_cell, output=decoded)\n","    autoencoder.compile(optimizer='rmsprop', loss='mse')\n","    autoencoder.fit(trainData_ae, trainTarget_ae, epochs=500, batch_size=128, shuffle=True,  validation_split=0.1,\n","                    callbacks=[mn.monitor(), cb.EarlyStopping(monitor='val_loss', patience=25,  mode='auto')])    \n","    source = autoencoder.predict(source)\n","    target = autoencoder.predict(target)\n","\n","# rescale source to have zero mean and unit variance\n","# apply same transformation to the target\n","#preprocessor = prep.StandardScaler().fit(source)\n","#source = preprocessor.transform(source) \n","#target = preprocessor.transform(target)    \n","\n","#############################\n","######## train MMD net ######\n","#############################\n","\n","\n","calibInput = Input(shape=(inputDim,))\n","block1_bn1 = BatchNormalization()(calibInput)\n","block1_a1 = Activation('relu')(block1_bn1)\n","block1_w1 = Dense(mmdNetLayerSizes[0], activation='linear',kernel_regularizer=l2(l2_penalty), \n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a1) \n","block1_bn2 = BatchNormalization()(block1_w1)\n","block1_a2 = Activation('relu')(block1_bn2)\n","block1_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty),\n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block1_a2) \n","block1_output = add([block1_w2, calibInput])\n","block2_bn1 = BatchNormalization()(block1_output)\n","block2_a1 = Activation('relu')(block2_bn1)\n","block2_w1 = Dense(mmdNetLayerSizes[1], activation='linear',kernel_regularizer=l2(l2_penalty), \n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a1) \n","block2_bn2 = BatchNormalization()(block2_w1)\n","block2_a2 = Activation('relu')(block2_bn2)\n","block2_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty), \n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block2_a2) \n","block2_output = add([block2_w2, block1_output])\n","block3_bn1 = BatchNormalization()(block2_output)\n","block3_a1 = Activation('relu')(block3_bn1)\n","block3_w1 = Dense(mmdNetLayerSizes[1], activation='linear',kernel_regularizer=l2(l2_penalty), \n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a1) \n","block3_bn2 = BatchNormalization()(block3_w1)\n","block3_a2 = Activation('relu')(block3_bn2)\n","block3_w2 = Dense(inputDim, activation='linear',kernel_regularizer=l2(l2_penalty), \n","                  kernel_initializer=initializers.RandomNormal(stddev=1e-4))(block3_a2) \n","block3_output = add([block3_w2, block2_output])\n","\n","calibMMDNet = Model(inputs=calibInput, outputs=block3_output)\n","\n","# learning rate schedule\n","def step_decay(epoch):\n","    initial_lrate = 0.001\n","    drop = 0.1\n","    epochs_drop = 150.0\n","    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n","    return lrate\n","lrate = LearningRateScheduler(step_decay)\n","\n","#train MMD net\n","optimizer = keras.optimizers.rmsprop(lr=0.0)\n","\n","calibMMDNet.compile(optimizer=optimizer, loss=lambda y_true,y_pred: \n","               cf.MMD(block3_output,target,MMDTargetValidation_split=0.1).KerasCost(y_true,y_pred))\n","K.get_session().run(tf.global_variables_initializer())\n","\n","sourceLabels = np.zeros(source.shape[0])\n","calibMMDNet.fit(source,sourceLabels,nb_epoch=500,batch_size=1000,validation_split=0.1,verbose=1,\n","           callbacks=[lrate, mn.monitorMMD(source, target, calibMMDNet.predict),\n","                      cb.EarlyStopping(monitor='val_loss',patience=50,mode='auto')])\n","\n","##############################\n","###### evaluate results ######\n","##############################\n","\n","calibratedSource = calibMMDNet.predict(source)\n","\n","##################################### qualitative evaluation: PCA #####################################\n","pca = decomposition.PCA()\n","pca.fit(target)\n","\n","# project data onto PCs\n","target_sample_pca = pca.transform(target)\n","projection_before = pca.transform(source)\n","projection_after = pca.transform(calibratedSource)\n","\n","# choose PCs to plot\n","pc1 = 0\n","pc2 = 1\n","axis1 = 'PC'+str(pc1)\n","axis2 = 'PC'+str(pc2)\n","sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], projection_before[:,pc2], axis1, axis2)\n","sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_after[:,pc1], projection_after[:,pc2], axis1, axis2)\n"," \n","'''\n","# save models\n","autoencoder.save(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_DAE.h5'))                 \n","calibMMDNet.save_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_ResNet_weights.h5'))  \n","'''\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["242756\n","242756\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","setting scales using KNN\n","[2.2277150035916926, 4.455430007183385, 8.91086001436677]\n","setting all scale weights to 1\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:183: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 218480 samples, validate on 24276 samples\n","Epoch 1/500\n","218480/218480 [==============================] - 8s 36us/step - loss: 0.2560 - val_loss: 0.4213\n","Epoch 2/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1828 - val_loss: 0.4006\n","Epoch 3/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1756 - val_loss: 0.3890\n","Epoch 4/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1715 - val_loss: 0.3897\n","Epoch 5/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1690 - val_loss: 0.3885\n","Epoch 6/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1668 - val_loss: 0.3774\n","Epoch 7/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1647 - val_loss: 0.3796\n","Epoch 8/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1627 - val_loss: 0.3768\n","Epoch 9/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1618 - val_loss: 0.3748\n","Epoch 10/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1605 - val_loss: 0.3750\n","Epoch 11/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1599 - val_loss: 0.3732\n","Epoch 12/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1581 - val_loss: 0.3680\n","Epoch 13/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1580 - val_loss: 0.3692\n","Epoch 14/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1570 - val_loss: 0.3677\n","Epoch 15/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1565 - val_loss: 0.3717\n","Epoch 16/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1553 - val_loss: 0.3633\n","Epoch 17/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1553 - val_loss: 0.3754\n","Epoch 18/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1545 - val_loss: 0.3701\n","Epoch 19/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1545 - val_loss: 0.3637\n","Epoch 20/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1541 - val_loss: 0.3643\n","Epoch 21/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1540 - val_loss: 0.3624\n","Epoch 22/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1535 - val_loss: 0.3603\n","Epoch 23/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1531 - val_loss: 0.3629\n","Epoch 24/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1527 - val_loss: 0.3568\n","Epoch 25/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1515 - val_loss: 0.3612\n","Epoch 26/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1519 - val_loss: 0.3625\n","Epoch 27/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1510 - val_loss: 0.3610\n","Epoch 28/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1507 - val_loss: 0.3575\n","Epoch 29/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1507 - val_loss: 0.3637\n","Epoch 30/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1500 - val_loss: 0.3578\n","Epoch 31/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1505 - val_loss: 0.3600\n","Epoch 32/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1502 - val_loss: 0.3535\n","Epoch 33/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1498 - val_loss: 0.3544\n","Epoch 34/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1499 - val_loss: 0.3536\n","Epoch 35/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1493 - val_loss: 0.3532\n","Epoch 36/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1495 - val_loss: 0.3525\n","Epoch 37/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1495 - val_loss: 0.3603\n","Epoch 38/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1483 - val_loss: 0.3529\n","Epoch 39/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1480 - val_loss: 0.3557\n","Epoch 40/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1482 - val_loss: 0.3567\n","Epoch 41/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1480 - val_loss: 0.3540\n","Epoch 42/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1487 - val_loss: 0.3490\n","Epoch 43/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1484 - val_loss: 0.3538\n","Epoch 44/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1480 - val_loss: 0.3491\n","Epoch 45/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1469 - val_loss: 0.3639\n","Epoch 46/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1473 - val_loss: 0.3643\n","Epoch 47/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1474 - val_loss: 0.3549\n","Epoch 48/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1466 - val_loss: 0.3529\n","Epoch 49/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1467 - val_loss: 0.3595\n","Epoch 50/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1466 - val_loss: 0.3529\n","Epoch 51/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1466 - val_loss: 0.3587\n","Epoch 52/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1474 - val_loss: 0.3484\n","Epoch 53/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1470 - val_loss: 0.3617\n","Epoch 54/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1464 - val_loss: 0.3560\n","Epoch 55/500\n","218480/218480 [==============================] - 6s 25us/step - loss: 0.1460 - val_loss: 0.3524\n","Epoch 56/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1458 - val_loss: 0.3592\n","Epoch 57/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1462 - val_loss: 0.3590\n","Epoch 58/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1459 - val_loss: 0.3626\n","Epoch 59/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1463 - val_loss: 0.3563\n","Epoch 60/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1456 - val_loss: 0.3543\n","Epoch 61/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1457 - val_loss: 0.3496\n","Epoch 62/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1448 - val_loss: 0.3574\n","Epoch 63/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1454 - val_loss: 0.3529\n","Epoch 64/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1454 - val_loss: 0.3452\n","Epoch 65/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1447 - val_loss: 0.3603\n","Epoch 66/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1455 - val_loss: 0.3560\n","Epoch 67/500\n","218480/218480 [==============================] - 6s 26us/step - loss: 0.1447 - val_loss: 0.3483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PFxPnAzBPBYg","colab_type":"code","colab":{}},"source":["from google.colab import files\n","import csv\n","\n","with open('/content/drive/My Drive/BatchEffectRemoval-master/Data/OUH16_no_scale_calib.csv', \"w\") as f:\n","    csv_w = csv.writer(f, lineterminator='\\n')\n","    csv_w.writerows(calibratedSource)\n","\n","#with open('/content/drive/My Drive/BatchEffectRemoval-master/Data/OUH05_calib.csv', \"w\") as f:\n","#    csv_w = csv.writer(f, lineterminator='\\n')\n","#    csv_w.writerows(target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4-pXb1ihNAg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}